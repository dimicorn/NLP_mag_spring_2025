{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRC5Mk7DS7il"
      },
      "source": [
        "# BiLSTM и CRF [(взято отсюда)](https://github.com/aminaghoul/NER-PyTorch?tab=readme-ov-file)\n",
        "\n",
        "В этом ноутбуке мы используем условные случайные поля (Conditional Random Fields, или CRF), которые часто применяются для задачи распознавания именованных сущностей (Named Entity Recognition) с целью предсказания корректных последовательностей меток.  \n",
        "Например, не должно быть ситуации, когда за меткой `B-PER` сразу следует другая метка `B-PER`.  \n",
        "Для реализации CRF мы будем использовать пакет [pytorch-crf](https://github.com/kmkurn/pytorch-crf).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FZ7KdEYMXqTP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q torchtext==0.6.0\n",
        "%pip install -q pytorch-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDTnd9P1YKi6",
        "outputId": "0c3684d6-b79c-4640-c705-b632f1861730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'NER-PyTorch' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/aminaghoul/NER-PyTorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s7pqLoSXKbh6"
      },
      "outputs": [],
      "source": [
        "#!pip install torchtext==0.6.0\n",
        "#!pip install pytorch-crf\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "# from torchtext.data import Field, NestedField, BucketIterator\n",
        "# from torchtext.datasets import SequenceTaggingDataset\n",
        "# from torchtext.vocab import Vocab\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext import data\n",
        "# from torchtext import datasets\n",
        "\n",
        "import spacy\n",
        "from torchcrf import CRF\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "import random\n",
        "import string\n",
        "from itertools import chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install spacy torchcrf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4LF_qyLKvfK"
      },
      "source": [
        "# Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JAamZSXiKnJl"
      },
      "outputs": [],
      "source": [
        "# pour la reproductibilité\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(lower = False)\n",
        "TAG = data.Field(unk_token = None) # les tags sont tous connus on a alors unk_token = None\n",
        "\n",
        "my_path = \"NER-PyTorch/data/\"\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "        path= my_path ,\n",
        "        train=\"train.csv\",\n",
        "        validation=\"valid.csv\",\n",
        "        test=\"test.csv\", format='csv', skip_header=True,\n",
        "        fields=((\"text\", TEXT), (\"tag\", TAG))\n",
        "    )\n",
        "MIN_FREQ = 0\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 min_freq = MIN_FREQ, # les mots qui apparaissent moins que MIN_FREQ fois seront ignorés du vocabulaire\n",
        "                 vectors = \"glove.6B.100d\",\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "\n",
        "TAG.build_vocab(train_data)\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = 'cpu'\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device, sort=False)\n",
        "\n",
        "# padding index\n",
        "TEXT_PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "TAG_PAD_IDX = TAG.vocab.stoi[TAG.pad_token]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXY-SyrWKx4u"
      },
      "source": [
        "## Построение модели\n",
        "\n",
        "В классе модели предусмотрены три ключевых изменения:\n",
        "\n",
        "1. **Подготовка слоя CRF при инициализации**  \n",
        "   Необходимо создать слой CRF и указать количество возможных тегов в тексте. Это позволит модели правильно обрабатывать предсказания последовательностей.\n",
        "\n",
        "2. **Включение логики слоя CRF в метод `forward()`**  \n",
        "   Это важное изменение: из-за особенностей реализации в пакете [`pytorch-crf`](https://github.com/kmkurn/pytorch-crf) теперь **расчёт потерь (loss)** выполняется прямо внутри `forward()`. Ранее прямой проход (forward pass) и вычисление потерь выполнялись отдельно — теперь они объединены, что упрощает код и делает обучение более прозрачным.\n",
        "\n",
        "3. **Инициализация невозможных переходов в CRF**  \n",
        "   В функции `init_crf_transitions` мы устанавливаем очень низкое значение (например, -100) для переходов между тегами, которые **нарушают BIO-логику**. Таким образом, модель \"понимает\", что такие переходы нежелательны и практически невозможны (например, `I-ORG` без предшествующего `B-ORG`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PW8shLquKyr-"
      },
      "outputs": [],
      "source": [
        "class BiLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 lstm_layers,\n",
        "                 emb_dropout,\n",
        "                 lstm_dropout,\n",
        "                 fc_dropout,\n",
        "                 word_pad_idx,\n",
        "                 tag_pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # LAYER 1: Word Embedding\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=input_dim,\n",
        "            embedding_dim=embedding_dim,\n",
        "            padding_idx=word_pad_idx\n",
        "        )\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "\n",
        "        # LAYER 2: BiLSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            bidirectional=True,\n",
        "            dropout=lstm_dropout if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # LAYER 3: Fully-connected\n",
        "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        # LAYER 4: CRF\n",
        "\n",
        "        self.tag_pad_idx = tag_pad_idx\n",
        "        self.crf = CRF(num_tags=output_dim)\n",
        "\n",
        "        # init poids avec distribution normale\n",
        "        for name, param in self.named_parameters():\n",
        "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "\n",
        "    def forward(self, words, tags=None):\n",
        "\n",
        "        # words = [sentence length, batch size]\n",
        "        # chars = [batch size, sentence length, word length)\n",
        "        # tags = [sentence length, batch size]\n",
        "\n",
        "        # embedding_out = [sentence length, batch size, embedding dim]\n",
        "        embedding_out = self.emb_dropout(self.embedding(words))\n",
        "\n",
        "        # lstm_out = [sentence length, batch size, hidden dim * 2]\n",
        "        lstm_out, _ = self.lstm(embedding_out)\n",
        "\n",
        "        # fc_out = [sentence length, batch size, output dim]\n",
        "        fc_out = self.fc(self.fc_dropout(lstm_out))\n",
        "\n",
        "        if tags is not None:\n",
        "            mask = tags != self.tag_pad_idx\n",
        "            crf_out = self.crf.decode(fc_out, mask=mask)\n",
        "            crf_loss = -self.crf(fc_out, tags=tags, mask=mask)\n",
        "        else:\n",
        "            crf_out = self.crf.decode(fc_out)\n",
        "            crf_loss = None\n",
        "\n",
        "        return crf_out , crf_loss\n",
        "\n",
        "\n",
        "\n",
        "    def init_crf_transitions(self, tag_names, imp_value=-100):\n",
        "        num_tags = len(tag_names)\n",
        "        for i in range(num_tags):\n",
        "            tag_name = tag_names[i]\n",
        "            # I and <pad> impossible au début\n",
        "            if tag_name[0] == \"I\" or tag_name == \"<pad>\":\n",
        "                torch.nn.init.constant_(self.crf.start_transitions[i], imp_value)\n",
        "        # transition impossible O - I\n",
        "        tag_is = {}\n",
        "        for tag_position in (\"B\", \"I\", \"O\"):\n",
        "            tag_is[tag_position] = [i for i, tag in enumerate(tag_names) if tag[0] == tag_position]\n",
        "        impossible_transitions_position = {\n",
        "            \"O\": \"I\"\n",
        "\n",
        "        }\n",
        "        for from_tag, to_tag_list in impossible_transitions_position.items():\n",
        "            to_tags = list(to_tag_list)\n",
        "\n",
        "            for from_tag_i in tag_is[from_tag]:\n",
        "                for to_tag in to_tags:\n",
        "                    for to_tag_i in tag_is[to_tag]:\n",
        "\n",
        "                        torch.nn.init.constant_(\n",
        "                            self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
        "                        )\n",
        "        # transitions impossibles entre différents types\n",
        "        impossible_transitions_tags = {\n",
        "            \"B\": \"I\",\n",
        "            \"I\": \"I\"\n",
        "        }\n",
        "        for from_tag, to_tag_list in impossible_transitions_tags.items():\n",
        "            to_tags = list(to_tag_list)\n",
        "            for from_tag_i in tag_is[from_tag]:\n",
        "                for to_tag in to_tags:\n",
        "                    for to_tag_i in tag_is[to_tag]:\n",
        "                        if tag_names[from_tag_i].split(\"-\")[1] != tag_names[to_tag_i].split(\"-\")[1]:\n",
        "                            torch.nn.init.constant_(\n",
        "                                self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
        "                            )\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb03iYctNAUM",
        "outputId": "933b9134-9598-44ca-cafa-73464b7030df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "У модели 3,101,034 обучаемых параметров.\n"
          ]
        }
      ],
      "source": [
        "embedding_dim=100\n",
        "tag_pad_idx=TAG_PAD_IDX\n",
        "model = BiLSTM(\n",
        "    input_dim=len(TEXT.vocab),\n",
        "    embedding_dim=100,\n",
        "    hidden_dim=256,\n",
        "    output_dim=len(TAG.vocab),\n",
        "    lstm_layers=1,\n",
        "    emb_dropout=0.1,\n",
        "    lstm_dropout=0.1,\n",
        "    fc_dropout=0.1,\n",
        "    word_pad_idx=TEXT_PAD_IDX,\n",
        "    tag_pad_idx=TAG_PAD_IDX\n",
        ")\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.embedding.weight.data[tag_pad_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "\n",
        "# CRF transitions initialisation\n",
        "model.init_crf_transitions(\n",
        "    tag_names=TAG.vocab.itos\n",
        ")\n",
        "\n",
        "print(f\"У модели {model.count_parameters():,} обучаемых параметров.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGsjeyHlyWhx"
      },
      "source": [
        "Мы можем получить доступ к матрице переходов и убедиться, что инициализация выполнена корректно:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfe5T7dlrS2j",
        "outputId": "e9afb59c-aa8f-4ee1-9aaa-fb90f2d0673f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start and end tag transitions:\n",
            "TAG   \tSTART\tEND\n",
            "<pad> \t-100.0\t-0.01\n",
            "O     \t-0.04\t-0.03\n",
            "B-LOC \t0.06\t-0.18\n",
            "B-PER \t0.02\t-0.04\n",
            "B-ORG \t0.05\t0.09\n",
            "I-PER \t-100.0\t0.1\n",
            "I-ORG \t-100.0\t0.1\n",
            "B-MISC\t-0.02\t0.07\n",
            "I-LOC \t-100.0\t0.1\n",
            "I-MISC\t-100.0\t0.09\n",
            "\n",
            "Between tags transitions:\n",
            "   TO\tO    \tB-PER\tI-PER\n",
            "FROM\n",
            "O    \t-0.01\t0.04 \t-100.0\n",
            "B-PER\t-0.15\t-0.06\t0.02 \n",
            "I-PER\t-0.06\t0.04 \t-0.03\n"
          ]
        }
      ],
      "source": [
        "def print_crf_transitions(c, m):\n",
        "    tags = TAG.vocab.itos\n",
        "    max_len_tag = max([len(tag) for tag in tags])\n",
        "    print(\"Start and end tag transitions:\")\n",
        "    print(f\"{'TAG'.ljust(max_len_tag)}\\tSTART\\tEND\")\n",
        "    for tag, start_prob, end_prob in zip(tags, m.crf.start_transitions.tolist(), m.crf.end_transitions.tolist()):\n",
        "        print(f\"{tag.ljust(max_len_tag)}\\t{round(start_prob, 2)}\\t{round(end_prob, 2)}\")\n",
        "    print()\n",
        "    print(\"Between tags transitions:\")\n",
        "    persons_i = [i for i, tag in enumerate(TAG.vocab.itos) if \"PER\" in tag or tag == \"O\"]\n",
        "    max_len_tag = max([len(tag) for tag in TAG.vocab.itos if \"PER\" in tag ])\n",
        "    transitions = m.crf.transitions\n",
        "    to_tags = \"TO\".rjust(max_len_tag) + \"\\t\" + \"\\t\".join([tag.ljust(max_len_tag) for tag in tags if \"PER\" in tag or tag == \"O\"])\n",
        "    print(to_tags)\n",
        "    print(\"FROM\")\n",
        "    for from_tag_i, from_tag_probs in enumerate(transitions[persons_i]):\n",
        "        to_tag_str = f\"{tags[persons_i[from_tag_i]].ljust(max_len_tag)}\"\n",
        "        for to_tag_prob in from_tag_probs[persons_i]:\n",
        "            to_tag_str += f\"\\t{str(round(to_tag_prob.item(), 2)).ljust(max_len_tag)}\"\n",
        "        print(to_tag_str)\n",
        "\n",
        "print_crf_transitions(TEXT, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lWbTw3yMiyr"
      },
      "source": [
        "## Обучение\n",
        "\n",
        "Модель возвращает два значения: список предсказаний и список потерь.  \n",
        "Мы учитываем эту особенность, изменяя функцию вычисления accuracy (точности).\n",
        "\n",
        "- Оптимизатор\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lNju-li7XHHh"
      },
      "outputs": [],
      "source": [
        "def optimiseur(model, lr=1e-5, eps=1e-6, weight_decay_rate=0.001, second_weight_decay_rate=0.0):\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "            'weight_decay_rate': weight_decay_rate},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "            'weight_decay_rate': second_weight_decay_rate}]\n",
        "    return optim.Adam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "        eps=eps\n",
        "    )\n",
        "\n",
        "optimizer = optimiseur(model, lr=1e-5, eps=1e-6, weight_decay_rate=0.001, second_weight_decay_rate=0.0)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC39UtslXHHh"
      },
      "source": [
        " - Метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vFxG-oKmXHHh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "def f1_loss( preds, y, tag_pad_idx, full_report=False):\n",
        "    index_o = TAG.vocab.stoi[\"O\"]\n",
        "    positive_labels = [i for i in range(len(TAG.vocab.itos))\n",
        "                       if i not in (tag_pad_idx, index_o)]\n",
        "\n",
        "    flatten_preds = [pred for sent_pred in preds for pred in sent_pred]\n",
        "\n",
        "    positive_preds = [pred for pred in flatten_preds\n",
        "                      if pred not in (tag_pad_idx, index_o)]\n",
        "\n",
        "    flatten_y = [tag for sent_tag in y for tag in sent_tag]\n",
        "    if full_report:\n",
        "\n",
        "        positive_names = [TAG.vocab.itos[i]\n",
        "                              for i in range(len(TAG.vocab.itos))\n",
        "                              if i not in (tag_pad_idx, index_o)]\n",
        "        print(classification_report(\n",
        "                y_true=flatten_y,\n",
        "                y_pred=flatten_preds,\n",
        "                labels=positive_labels,\n",
        "                target_names=positive_names\n",
        "            ))\n",
        "\n",
        "    return f1_score(\n",
        "            y_true=flatten_y,\n",
        "            y_pred=flatten_preds,\n",
        "            labels=positive_labels,\n",
        "            average=\"micro\"\n",
        "        ), flatten_preds, flatten_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m77BrecGXHHh"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, tag_pad_idx):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_f1 = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "        text = batch.text\n",
        "        tags = batch.tag\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred_tags_list, batch_loss = model(text, tags)\n",
        "\n",
        "        # pour calculer la loss et le score f1, on flatten true tags\n",
        "        true_tags_list = [\n",
        "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
        "                for sent_tag in tags.permute(1, 0).tolist()\n",
        "            ]\n",
        "        f1,_,_ = f1_loss(pred_tags_list, true_tags_list, tag_pad_idx)\n",
        "\n",
        "        batch_loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_loss += batch_loss.item()\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_f1 / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, tag_pad_idx,full_report):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch.text\n",
        "            tags = batch.tag\n",
        "\n",
        "            pred_tags_list, batch_loss = model(text, tags)\n",
        "            true_tags_list = [\n",
        "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
        "                for sent_tag in tags.permute(1, 0).tolist()\n",
        "                ]\n",
        "\n",
        "            f1, pred, lab = f1_loss(pred_tags_list, true_tags_list, tag_pad_idx, full_report)\n",
        "            preds.append(pred)\n",
        "            labels.append(lab)\n",
        "            epoch_loss += batch_loss.item()\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_f1 / len(iterator),preds, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOfrodkZeXpE"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Epoch: 01 | Epoch Time: 0m 58s\n",
        "\tTrain Loss: 241.116 | Train F1 score: 3.01%\n",
        "\t Val. Loss: 166.222 |  Val. F1 score: 0.00%\n",
        "Epoch: 02 | Epoch Time: 0m 53s\n",
        "\tTrain Loss: 129.382 | Train F1 score: 0.63%\n",
        "\t Val. Loss: 152.273 |  Val. F1 score: 0.02%\n",
        "Epoch: 03 | Epoch Time: 1m 2s\n",
        "\tTrain Loss: 120.049 | Train F1 score: 1.81%\n",
        "\t Val. Loss: 140.780 |  Val. F1 score: 0.06%\n",
        "Epoch: 04 | Epoch Time: 0m 57s\n",
        "\tTrain Loss: 114.141 | Train F1 score: 2.86%\n",
        "\t Val. Loss: 133.491 |  Val. F1 score: 0.19%\n",
        "Epoch: 05 | Epoch Time: 0m 54s\n",
        "\tTrain Loss: 109.274 | Train F1 score: 4.14%\n",
        "\t Val. Loss: 124.549 |  Val. F1 score: 0.60%\n",
        "Epoch: 06 | Epoch Time: 0m 53s\n",
        "\tTrain Loss: 104.033 | Train F1 score: 6.44%\n",
        "\t Val. Loss: 118.140 |  Val. F1 score: 0.93%\n",
        "Epoch: 07 | Epoch Time: 0m 53s\n",
        "\tTrain Loss: 99.721 | Train F1 score: 8.20%\n",
        "\t Val. Loss: 111.239 |  Val. F1 score: 1.79%\n",
        "Epoch: 08 | Epoch Time: 0m 53s\n",
        "\tTrain Loss: 95.569 | Train F1 score: 11.03%\n",
        "\t Val. Loss: 103.776 |  Val. F1 score: 3.39%\n",
        "Epoch: 09 | Epoch Time: 0m 53s\n",
        "\tTrain Loss: 91.957 | Train F1 score: 13.15%\n",
        "\t Val. Loss: 98.588 |  Val. F1 score: 6.02%\n",
        "Epoch: 10 | Epoch Time: 0m 52s\n",
        "\tTrain Loss: 88.829 | Train F1 score: 15.47%\n",
        "\t Val. Loss: 95.323 |  Val. F1 score: 8.55%\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "_fA42zRlXHHi",
        "outputId": "954dc178-504c-4827-ec6f-c95848dc1681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 17s\n",
            "\tTrain Loss: 186.241 | Train F1 score: 3.37%\n",
            "\t Val. Loss: 130.382 |  Val. F1 score: 1.06%\n",
            "Epoch: 02 | Epoch Time: 1m 14s\n",
            "\tTrain Loss: 104.009 | Train F1 score: 6.53%\n",
            "\t Val. Loss: 106.353 |  Val. F1 score: 5.76%\n",
            "Epoch: 03 | Epoch Time: 1m 12s\n",
            "\tTrain Loss: 90.143 | Train F1 score: 14.13%\n",
            "\t Val. Loss: 93.258 |  Val. F1 score: 13.10%\n",
            "Epoch: 04 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 81.389 | Train F1 score: 21.70%\n",
            "\t Val. Loss: 84.611 |  Val. F1 score: 20.70%\n",
            "Epoch: 05 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 75.100 | Train F1 score: 28.07%\n",
            "\t Val. Loss: 78.923 |  Val. F1 score: 26.41%\n",
            "Epoch: 06 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 70.331 | Train F1 score: 33.05%\n",
            "\t Val. Loss: 74.322 |  Val. F1 score: 31.32%\n",
            "Epoch: 07 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 66.203 | Train F1 score: 37.53%\n",
            "\t Val. Loss: 70.568 |  Val. F1 score: 34.99%\n",
            "Epoch: 08 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 62.971 | Train F1 score: 40.81%\n",
            "\t Val. Loss: 67.445 |  Val. F1 score: 39.31%\n",
            "Epoch: 09 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 60.071 | Train F1 score: 45.04%\n",
            "\t Val. Loss: 65.142 |  Val. F1 score: 42.21%\n",
            "Epoch: 10 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 57.500 | Train F1 score: 46.98%\n",
            "\t Val. Loss: 62.518 |  Val. F1 score: 46.19%\n",
            "Epoch: 11 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 55.772 | Train F1 score: 49.45%\n",
            "\t Val. Loss: 61.966 |  Val. F1 score: 47.17%\n",
            "Epoch: 12 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 54.735 | Train F1 score: 50.40%\n",
            "\t Val. Loss: 61.276 |  Val. F1 score: 48.03%\n",
            "Epoch: 13 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 53.644 | Train F1 score: 52.00%\n",
            "\t Val. Loss: 60.400 |  Val. F1 score: 49.10%\n",
            "Epoch: 14 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 52.835 | Train F1 score: 52.86%\n",
            "\t Val. Loss: 59.544 |  Val. F1 score: 50.03%\n",
            "Epoch: 15 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 51.697 | Train F1 score: 54.28%\n",
            "\t Val. Loss: 59.082 |  Val. F1 score: 50.52%\n",
            "Epoch: 16 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 50.992 | Train F1 score: 54.56%\n",
            "\t Val. Loss: 58.311 |  Val. F1 score: 51.76%\n",
            "Epoch: 17 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 50.126 | Train F1 score: 55.98%\n",
            "\t Val. Loss: 57.942 |  Val. F1 score: 52.68%\n",
            "Epoch: 18 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 49.589 | Train F1 score: 56.77%\n",
            "\t Val. Loss: 57.261 |  Val. F1 score: 53.41%\n",
            "Epoch: 19 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 48.619 | Train F1 score: 57.50%\n",
            "\t Val. Loss: 56.776 |  Val. F1 score: 54.04%\n",
            "Epoch: 20 | Epoch Time: 1m 7s\n",
            "\tTrain Loss: 47.978 | Train F1 score: 58.13%\n",
            "\t Val. Loss: 56.553 |  Val. F1 score: 54.12%\n",
            "Epoch: 21 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 47.411 | Train F1 score: 59.14%\n",
            "\t Val. Loss: 55.806 |  Val. F1 score: 54.88%\n",
            "Epoch: 22 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 47.108 | Train F1 score: 58.74%\n",
            "\t Val. Loss: 55.476 |  Val. F1 score: 55.45%\n",
            "Epoch: 23 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 46.744 | Train F1 score: 59.07%\n",
            "\t Val. Loss: 55.504 |  Val. F1 score: 55.24%\n",
            "Epoch: 24 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 46.518 | Train F1 score: 59.87%\n",
            "\t Val. Loss: 55.259 |  Val. F1 score: 55.61%\n",
            "Epoch: 25 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 46.223 | Train F1 score: 60.04%\n",
            "\t Val. Loss: 54.995 |  Val. F1 score: 55.84%\n",
            "Epoch: 26 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 45.862 | Train F1 score: 60.41%\n",
            "\t Val. Loss: 54.765 |  Val. F1 score: 56.22%\n",
            "Epoch: 27 | Epoch Time: 1m 6s\n",
            "\tTrain Loss: 45.483 | Train F1 score: 60.85%\n",
            "\t Val. Loss: 54.797 |  Val. F1 score: 56.55%\n",
            "Epoch: 28 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 45.227 | Train F1 score: 61.11%\n",
            "\t Val. Loss: 54.637 |  Val. F1 score: 56.64%\n",
            "Epoch: 29 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 44.796 | Train F1 score: 61.30%\n",
            "\t Val. Loss: 54.403 |  Val. F1 score: 56.88%\n",
            "Epoch: 30 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 44.563 | Train F1 score: 61.77%\n",
            "\t Val. Loss: 54.456 |  Val. F1 score: 56.84%\n",
            "Epoch: 31 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 44.359 | Train F1 score: 61.95%\n",
            "\t Val. Loss: 54.125 |  Val. F1 score: 57.36%\n",
            "Epoch: 32 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 44.305 | Train F1 score: 61.59%\n",
            "\t Val. Loss: 53.882 |  Val. F1 score: 57.78%\n",
            "Epoch: 33 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 44.116 | Train F1 score: 62.38%\n",
            "\t Val. Loss: 53.912 |  Val. F1 score: 57.74%\n",
            "Epoch: 34 | Epoch Time: 1m 7s\n",
            "\tTrain Loss: 43.835 | Train F1 score: 62.29%\n",
            "\t Val. Loss: 53.870 |  Val. F1 score: 57.80%\n",
            "Epoch: 35 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 43.866 | Train F1 score: 62.34%\n",
            "\t Val. Loss: 53.556 |  Val. F1 score: 58.08%\n",
            "Epoch: 36 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 43.703 | Train F1 score: 62.48%\n",
            "\t Val. Loss: 53.707 |  Val. F1 score: 58.21%\n",
            "Epoch: 37 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 43.547 | Train F1 score: 62.53%\n",
            "\t Val. Loss: 53.760 |  Val. F1 score: 57.98%\n",
            "Epoch: 38 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 43.425 | Train F1 score: 62.35%\n",
            "\t Val. Loss: 53.284 |  Val. F1 score: 58.47%\n",
            "Epoch: 39 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 43.279 | Train F1 score: 63.16%\n",
            "\t Val. Loss: 53.582 |  Val. F1 score: 58.30%\n",
            "Epoch: 40 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 43.233 | Train F1 score: 62.89%\n",
            "\t Val. Loss: 53.473 |  Val. F1 score: 58.66%\n",
            "Epoch: 41 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 43.070 | Train F1 score: 62.73%\n",
            "\t Val. Loss: 53.289 |  Val. F1 score: 58.66%\n",
            "Epoch: 42 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 43.012 | Train F1 score: 63.27%\n",
            "\t Val. Loss: 53.213 |  Val. F1 score: 58.86%\n",
            "Epoch: 43 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 42.875 | Train F1 score: 62.87%\n",
            "\t Val. Loss: 53.083 |  Val. F1 score: 59.00%\n",
            "Epoch: 44 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 42.883 | Train F1 score: 63.31%\n",
            "\t Val. Loss: 53.140 |  Val. F1 score: 58.99%\n",
            "Epoch: 45 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 42.780 | Train F1 score: 63.17%\n",
            "\t Val. Loss: 53.251 |  Val. F1 score: 58.92%\n",
            "Epoch: 46 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 42.662 | Train F1 score: 63.44%\n",
            "\t Val. Loss: 53.043 |  Val. F1 score: 59.06%\n",
            "Epoch: 47 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 42.774 | Train F1 score: 63.06%\n",
            "\t Val. Loss: 52.947 |  Val. F1 score: 59.24%\n",
            "Epoch: 48 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 42.553 | Train F1 score: 63.45%\n",
            "\t Val. Loss: 52.947 |  Val. F1 score: 59.14%\n",
            "Epoch: 49 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 42.620 | Train F1 score: 63.78%\n",
            "\t Val. Loss: 52.913 |  Val. F1 score: 59.20%\n",
            "Epoch: 50 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 42.544 | Train F1 score: 63.48%\n",
            "\t Val. Loss: 53.023 |  Val. F1 score: 59.03%\n"
          ]
        }
      ],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "N_EPOCHS = 50\n",
        "\n",
        "t_loss = []\n",
        "t_f1 = []\n",
        "v_loss = []\n",
        "v_f1 = []\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "\n",
        "    train_loss, train_f1 = train(model, train_iterator, optimizer, TAG_PAD_IDX)\n",
        "    t_loss.append(train_loss)\n",
        "    t_f1.append(train_f1)\n",
        "\n",
        "    valid_loss, valid_f1,_,_ = evaluate(model, valid_iterator, TAG_PAD_IDX, full_report= False)\n",
        "    v_loss.append(valid_loss)\n",
        "    v_f1.append(valid_f1)\n",
        "\n",
        "    scheduler.step()\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model_conll.pt')\n",
        "\n",
        "\n",
        "    if epoch%1 == 0:\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train F1 score: {train_f1*100:.2f}%')\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. F1 score: {valid_f1*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "StI1POlxXHHi",
        "outputId": "6cab820d-d183-4cf8-8668-5bea370518c8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (12,) and (50,)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m N_EPOCHS_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, N_EPOCHS_real, N_EPOCHS_real)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x,v_loss)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/work/testing/eval-env/lib/python3.9/site-packages/matplotlib/pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/work/testing/eval-env/lib/python3.9/site-packages/matplotlib/axes/_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
            "File \u001b[0;32m~/work/testing/eval-env/lib/python3.9/site-packages/matplotlib/axes/_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/work/testing/eval-env/lib/python3.9/site-packages/matplotlib/axes/_base.py:486\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    483\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (12,) and (50,)"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "sns.set()\n",
        "N_EPOCHS_real = 12\n",
        "x = np.linspace(0, N_EPOCHS_real, N_EPOCHS_real)\n",
        "\n",
        "plt.plot(x,t_loss)\n",
        "plt.plot(x,v_loss)\n",
        "plt.title(\"Loss\")\n",
        "plt.legend([\"Train loss\", \"Valid loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJfvVaksXHHj",
        "outputId": "49553159-2e27-4b5e-86c3-3381d93f5beb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f703dbe3bd0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.linspace(0, N_EPOCHS_real,N_EPOCHS_real)\n",
        "\n",
        "plt.plot(x,t_f1)\n",
        "plt.plot(x,v_f1)\n",
        "plt.title(\"F1 score\")\n",
        "plt.legend([\"Train F1\", \"Valid F1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwJbyZ9HXHHj",
        "outputId": "ad6edd1a-5388-4af1-c440-286727415353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 51.947 |  Test F1 score: 52.48%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "model.load_state_dict(torch.load('tut3-model_conll.pt'))\n",
        "\n",
        "test_loss, test_f1, preds, labels = evaluate(model, test_iterator, TAG_PAD_IDX, full_report=False)\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test F1 score: {test_f1*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cykzd-8IXHHj"
      },
      "outputs": [],
      "source": [
        "predict =  [item for sublist in preds for item in sublist]\n",
        "true =  [item for sublist in labels for item in sublist]\n",
        "confusion = confusion_matrix(true, predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XubyQrpLXHHj"
      },
      "source": [
        "### Матрица ошибок\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWGcLPg0XHHj",
        "outputId": "0aff5217-5376-44fd-d307-cd868f75b352"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>O</th>\n",
              "      <th>LOC</th>\n",
              "      <th>PER</th>\n",
              "      <th>ORG</th>\n",
              "      <th>MISC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>38178</td>\n",
              "      <td>49</td>\n",
              "      <td>144</td>\n",
              "      <td>101</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>794</td>\n",
              "      <td>937</td>\n",
              "      <td>74</td>\n",
              "      <td>99</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>1282</td>\n",
              "      <td>25</td>\n",
              "      <td>1346</td>\n",
              "      <td>106</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>969</td>\n",
              "      <td>149</td>\n",
              "      <td>209</td>\n",
              "      <td>1115</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>524</td>\n",
              "      <td>35</td>\n",
              "      <td>28</td>\n",
              "      <td>46</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          O  LOC   PER   ORG  MISC\n",
              "O     38178   49   144   101    48\n",
              "LOC     794  937    74    99    20\n",
              "PER    1282   25  1346   106    12\n",
              "ORG     969  149   209  1115    51\n",
              "MISC    524   35    28    46   282"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_df =pd.DataFrame(confusion)\n",
        "\n",
        "confusion_df.columns=[i for i in TAG.vocab.itos]\n",
        "s = pd.Series([i for i in TAG.vocab.itos])\n",
        "confusion_df = confusion_df.set_index([s])\n",
        "\n",
        "confusion_df['LOC'] = confusion_df['B-LOC'] + confusion_df['I-LOC']\n",
        "confusion_df['PER'] = confusion_df['B-PER'] + confusion_df['I-PER']\n",
        "confusion_df['ORG'] = confusion_df['B-ORG'] + confusion_df['I-ORG']\n",
        "confusion_df['MISC'] = confusion_df['B-MISC'] + confusion_df['I-MISC']\n",
        "\n",
        "\n",
        "confusion_df = confusion_df.drop(columns=[ i for i in TAG.vocab.itos if i != 'O'])\n",
        "\n",
        "confusion_df.loc['LOC'] = confusion_df.loc['B-LOC'] + confusion_df.loc['I-LOC']\n",
        "confusion_df.loc['PER'] = confusion_df.loc['B-PER'] + confusion_df.loc['I-PER']\n",
        "confusion_df.loc['ORG'] = confusion_df.loc['B-ORG'] + confusion_df.loc['I-ORG']\n",
        "confusion_df.loc['MISC'] = confusion_df.loc['B-MISC'] + confusion_df.loc['I-MISC']\n",
        "\n",
        "confusion_df = confusion_df.drop([i for i in TAG.vocab.itos if i != 'O'  ])\n",
        "\n",
        "confusion_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgpzcOaVXHHk"
      },
      "source": [
        "### Precision-Recall-F1Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXmfXOIsXHHk",
        "outputId": "4e37e59a-b204-4f5f-fad2-cffc85dc1f19"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>0.914509</td>\n",
              "      <td>0.991121</td>\n",
              "      <td>0.951275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.784100</td>\n",
              "      <td>0.487006</td>\n",
              "      <td>0.600834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.747363</td>\n",
              "      <td>0.485745</td>\n",
              "      <td>0.588801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.760055</td>\n",
              "      <td>0.447252</td>\n",
              "      <td>0.563131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.682809</td>\n",
              "      <td>0.308197</td>\n",
              "      <td>0.424699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Precision    Recall  F1-score\n",
              "O      0.914509  0.991121  0.951275\n",
              "LOC    0.784100  0.487006  0.600834\n",
              "PER    0.747363  0.485745  0.588801\n",
              "ORG    0.760055  0.447252  0.563131\n",
              "MISC   0.682809  0.308197  0.424699"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm = confusion_df.to_numpy()\n",
        "\n",
        "TP = np.diag(cm)\n",
        "FP = np.sum(cm, axis=0) - TP\n",
        "FN = np.sum(cm, axis=1) - TP\n",
        "\n",
        "num_classes = 4\n",
        "TN = []\n",
        "for i in range(num_classes):\n",
        "    temp = np.delete(cm, i, 0)\n",
        "    temp = np.delete(temp, i, 1)\n",
        "    TN.append(sum(sum(temp)))\n",
        "\n",
        "precision = TP/(TP+FP)\n",
        "recall = TP/(TP+FN)\n",
        "f1 = (2*precision*recall)/(precision+recall)\n",
        "\n",
        "prf_df =pd.DataFrame()\n",
        "prf_df['Precision'] = precision\n",
        "prf_df['Recall'] = recall\n",
        "prf_df['F1-score'] = f1\n",
        "\n",
        "s = pd.Series([i for i in confusion_df.index])\n",
        "prf_df = prf_df.set_index([s])\n",
        "\n",
        "prf_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPbdtiKMXHHk"
      },
      "source": [
        "## Инференс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjMnCodQXHHk"
      },
      "outputs": [],
      "source": [
        "def tag_sentence(model, device, sentence, text_field, tag_field):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token for token in sentence]\n",
        "\n",
        "    if text_field.lower:\n",
        "        tokens = [t.lower() for t in tokens]\n",
        "\n",
        "    max_word_len = max([len(token) for token in tokens])\n",
        "\n",
        "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
        "    unk_idx = text_field.vocab.stoi[text_field.unk_token]\n",
        "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
        "\n",
        "    token_tensor = torch.as_tensor(numericalized_tokens)\n",
        "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
        "\n",
        "    predictions, _ = model(token_tensor)\n",
        "    predicted_tags = [tag_field.vocab.itos[t] for t in predictions[0]]\n",
        "\n",
        "    return tokens, predicted_tags, unks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KySUObzEXHHl",
        "outputId": "917ef476-2172-4d01-9d47-b6b36f8d4697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Trailing', 'by', '213', ',', 'Somerset', 'got', 'a', 'solid', 'start', 'to', 'their', 'second', 'innings', 'before', 'Simmons', 'stepped', 'in', 'to', 'bundle', 'them', 'out', 'for', '174', '.']\n",
            "['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "example_index = 6\n",
        "\n",
        "sentence = vars(valid_data.examples[example_index])['text']\n",
        "actual_tags = vars(valid_data.examples[example_index])['tag']\n",
        "\n",
        "print(sentence)\n",
        "print(actual_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jSGqRX8XHHl",
        "outputId": "99735be5-c439-45a0-94fc-b3a1016d0a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "tokens, pred_tags, unks = tag_sentence(model,\n",
        "                                       device,\n",
        "                                       sentence,\n",
        "                                       TEXT,\n",
        "                                       TAG\n",
        "                                      )\n",
        "print(pred_tags)\n",
        "print(actual_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V59bzJjLXHHl",
        "outputId": "6a68a279-6df2-4954-8e7a-3104b519218e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred. Tag\t\t\t\tActual Tag\t\t\t\tCorrect?\t\t\t\tToken\n",
            "\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t Trailing\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t by\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t 213\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t ,\n",
            "O \t\t\t\t\t B-ORG \t\t\t\t ✘ \t\t\t\t\t Somerset\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t got\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t a\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t solid\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t start\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t to\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t their\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t second\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t innings\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t before\n",
            "B-PER \t\t\t\t B-PER \t\t\t\t ✔ \t\t\t\t\t Simmons\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t stepped\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t in\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t to\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t bundle\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t them\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t out\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t for\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t 174\n",
            "O \t\t\t\t\t O \t\t\t\t\t ✔ \t\t\t\t\t .\n"
          ]
        }
      ],
      "source": [
        "print(\"Pred. Tag\\t\\t\\t\\tActual Tag\\t\\t\\t\\tCorrect?\\t\\t\\t\\tToken\\n\")\n",
        "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    space = 5 if pred_tag == 'O'else 4\n",
        "    space1 = 5 if actual_tag == 'O'else 4\n",
        "    print(pred_tag,\"\\t\"*space, actual_tag, \"\\t\"*space1, correct,\"\\t\"*5, token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "379kcA5_XHHl",
        "outputId": "d4b122f8-dc62-4daf-f62e-4e90d9123e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "Pred. Tag\tToken\n",
            "\n",
            "O \t\t The\n",
            "O \t\t will\n",
            "O \t\t deliver\n",
            "O \t\t a\n",
            "O \t\t speech\n",
            "O \t\t about\n",
            "O \t\t the\n",
            "O \t\t conflict\n",
            "O \t\t in\n",
            "B-LOC \t North\n",
            "I-LOC \t Korea\n",
            "O \t\t tomorrow\n",
            "O \t\t in\n",
            "B-LOC \t New\n",
            "I-LOC \t York\n",
            "O \t\t with\n",
            "O \t\t my\n",
            "O \t\t friend\n",
            "B-LOC \t Mary\n",
            "I-LOC \t Kate\n",
            "O \t\t .\n"
          ]
        }
      ],
      "source": [
        "sentence = 'The will deliver a speech about the conflict in North Korea tomorrow in New York with my friend Mary Kate.'\n",
        "tokens, tags, unks = tag_sentence(model,\n",
        "                                  device,\n",
        "                                  sentence,\n",
        "                                  TEXT,\n",
        "                                  TAG\n",
        "                                )\n",
        "\n",
        "print(unks)\n",
        "print(\"Pred. Tag\\tToken\\n\")\n",
        "\n",
        "\n",
        "for token, tag in zip(tokens, tags):\n",
        "    space = 2 if tag == 'O'else 1\n",
        "    print(tag, \"\\t\"*space, token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk2eXJ3nXHHm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "eval-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
